version: "3"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    volumes:
      - ./backend:/app
    environment:
      - NEO4J_URI="neo4j+s://0d46bd1d.databases.neo4j.io:7687"
      - NEO4J_PASSWORD="UPRd_VJ9KeA9T2l80jfanIH0OljSwu-MWyMgNtab42c"
      - NEO4J_USERNAME="neo4j"
      - NEO4J_DATABASE="neo4j"
      # - OPENAI_API_KEY=${OPENAI_API_KEY-}
      # - DIFFBOT_API_KEY=${DIFFBOT_API_KEY-}
      - EMBEDDING_MODEL="llama2"
      # - LANGCHAIN_ENDPOINT=${LANGCHAIN_ENDPOINT-}
      # - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2-}
      # - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT-}
      # - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY-}
      # - KNN_MIN_SCORE=${KNN_MIN_SCORE-0.94}
      - IS_EMBEDDING="False"
      # - GEMINI_ENABLED=${GEMINI_ENABLED-False}
      - OLLAMA_ENABLED="True"
      - GCP_LOG_METRICS_ENABLED=${GCP_LOG_METRICS_ENABLED-False}
      - UPDATE_GRAPH_CHUNKS_PROCESSED=${UPDATE_GRAPH_CHUNKS_PROCESSED-20}
      - NUMBER_OF_CHUNKS_TO_COMBINE=${NUMBER_OF_CHUNKS_TO_COMBINE-6}
      - ENTITY_EMBEDDING="False"
      - GCS_FILE_CACHE=${GCS_FILE_CACHE-False}
#      - LLM_MODEL_CONFIG_anthropic_claude_35_sonnet=${LLM_MODEL_CONFIG_anthropic_claude_35_sonnet-}
#      - LLM_MODEL_CONFIG_fireworks_llama_v3_70b=${LLM_MODEL_CONFIG_fireworks_llama_v3_70b-}
#      - LLM_MODEL_CONFIG_azure_ai_gpt_4o=${LLM_MODEL_CONFIG_azure_ai_gpt_4o-}
#      - LLM_MODEL_CONFIG_azure_ai_gpt_35=${LLM_MODEL_CONFIG_azure_ai_gpt_35-}
#      - LLM_MODEL_CONFIG_groq_llama3_70b=${LLM_MODEL_CONFIG_groq_llama3_70b-}
#      - LLM_MODEL_CONFIG_bedrock_claude_3_5_sonnet=${LLM_MODEL_CONFIG_bedrock_claude_3_5_sonnet-}
#     - LLM_MODEL_CONFIG_fireworks_qwen_72b=${LLM_MODEL_CONFIG_fireworks_qwen_72b-}
      - LLM_MODEL_CONFIG_llama_llama2="llama2"
    container_name: backend
    extra_hosts:
      - host.docker.internal:host-gateway
    ports:
      - "8000:8000"
    networks:
      - net

  frontend:
    depends_on:
      - backend
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - BACKEND_API_URL=${BACKEND_API_URL-http://localhost:8000}
        - REACT_APP_SOURCES=${REACT_APP_SOURCES-local,youtube,wiki,s3}
        - LLM_MODELS=${LLM_MODELS-diffbot,openai-gpt-3.5,openai-gpt-4o,llama2}
        - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID-""}
        - BLOOM_URL=${BLOOM_URL-https://workspace-preview.neo4j.io/workspace/explore?connectURL={CONNECT_URL}&search=Show+me+a+graph&featureGenAISuggestions=true&featureGenAISuggestionsInternal=true}
        - TIME_PER_CHUNK=${TIME_PER_CHUNK-4}
        - TIME_PER_PAGE=${TIME_PER_PAGE-50}
        - CHUNK_SIZE=${CHUNK_SIZE-5242880}
        - ENV=${ENV-DEV}
        - CHAT_MODES=${CHAT_MODES-""}
    volumes:
      - ./frontend:/app
      - /app/node_modules
    container_name: frontend
    ports:
      - "8080:8080"
    networks:
      - net

networks:
  net:
